{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e08a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2120c9e3",
   "metadata": {},
   "source": [
    "Defining the triggers and have a look at their timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ea7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.read_epochs(\"../sample/epochs/asjt-epo.fif.gz\", preload=True)\n",
    "epochs.pick(picks=\"eeg\")\n",
    "even_ids = epochs.event_id\n",
    "even_ids.pop(\"New Segment/\", None)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4), layout=\"tight\")\n",
    "mne.viz.plot_events(epochs.events, sfreq=1000, event_id=even_ids, axes=ax)\n",
    "ax.get_legend().remove()\n",
    "ax.spines[[\"right\", \"top\"]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make equal number of epochs for training (so random)\n",
    "rnd_ids = [key for key in even_ids if key.endswith(\"rndm\")]\n",
    "eps_list = [epochs[rnd_id] for rnd_id in rnd_ids]\n",
    "mne.epochs.equalize_epoch_counts(eps_list, method=\"mintime\")\n",
    "epochs_rnd = mne.concatenate_epochs(eps_list)\n",
    "\n",
    "ord_ids = [key for key in even_ids if key.endswith(\"or\")]\n",
    "epochs_ord = epochs[ord_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333027d5",
   "metadata": {},
   "source": [
    "a. train a classifier on the random condition (least predictable)\n",
    "\n",
    "b. test it on ordered sequences\n",
    "\n",
    "\n",
    "*This allows you to measure how much the brain's predictive pattern generalizes to more predictable contextsâ€”essentially quantifying prediction strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d829ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "X_train = epochs_rnd.get_data()  \n",
    "y_train = epochs_rnd.events[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2563303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mne.decoding import GeneralizingEstimator\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "# time-generalization (optional)\n",
    "time_gen = GeneralizingEstimator(clf, scoring='accuracy', n_jobs=1)\n",
    "time_gen.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test on predictive\n",
    "full_epochs = epochs['full']  # 100% predictable\n",
    "X_test = full_epochs.get_data()\n",
    "y_test = full_epochs.events[:, 2]\n",
    "\n",
    "scores = time_gen.score(X_test, y_test)  # decoding accuracy over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d30c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract clf weights\n",
    "import numpy as np\n",
    "\n",
    "# weights per channel\n",
    "weights = np.mean(time_gen.estimators_[0].coef_, axis=0)  # average across classes\n",
    "# can plot topomap\n",
    "mne.viz.plot_topomap(weights, epochs.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa90934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from mne.decoding import SlidingEstimator, cross_val_multiscore, GeneralizingEstimator\n",
    "\n",
    "# --- 1. Define your epochs and events ---\n",
    "# epochs: MNE Epochs object with your data\n",
    "# trigger_dict: dictionary mapping frequency to integer event ID\n",
    "# Example: trigger_dict = {'f500Hz': 1, 'f1000Hz': 2, 'f1500Hz': 3, 'f2000Hz': 4}\n",
    "\n",
    "# Select only the random sequence epochs for training\n",
    "random_epochs = epochs['random']  # adjust if you have a metadata column\n",
    "X_train = random_epochs.get_data()  # shape: (n_epochs, n_channels, n_times)\n",
    "y_train = random_epochs.events[:, 2]  # event IDs\n",
    "\n",
    "# --- 2. Time-resolved decoding ---\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "time_decod = SlidingEstimator(lda, scoring='accuracy', n_jobs=-1)\n",
    "scores = cross_val_multiscore(time_decod, X_train, y_train, cv=5)  # 5-fold CV\n",
    "scores_mean = np.mean(scores, axis=0)  # mean over CV folds\n",
    "\n",
    "# --- 3. Temporal Generalization ---\n",
    "gen_estimator = GeneralizingEstimator(lda, scoring='accuracy', n_jobs=-1)\n",
    "gen_estimator.fit(X_train, y_train)  # fit on post-stimulus\n",
    "temporal_gen_scores = gen_estimator.score(X_train, y_train)  # time x time matrix\n",
    "\n",
    "# --- 4. Cross-decoding: train on random, test on ordered ---\n",
    "ordered_epochs = epochs['ordered']\n",
    "X_test = ordered_epochs.get_data()\n",
    "y_test = ordered_epochs.events[:, 2]\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "cross_decoding_scores = np.array([lda.score(X_test[:, :, t], y_test) for t in range(X_test.shape[2])])\n",
    "\n",
    "# --- 5. Train post-stimulus, test pre-stimulus (random tones) ---\n",
    "# Assuming epochs.time gives the time vector\n",
    "post_idx = np.where(epochs.times >= 0)[0]  # post-stimulus\n",
    "pre_idx = np.where(epochs.times < 0)[0]   # pre-stimulus\n",
    "\n",
    "X_post = X_train[:, :, post_idx]\n",
    "X_pre = X_train[:, :, pre_idx]\n",
    "\n",
    "lda.fit(X_post, y_train)\n",
    "pre_stim_scores = np.array([lda.score(X_pre[:, :, t], y_train) for t in range(X_pre.shape[2])])\n",
    "\n",
    "# --- 6. Optional: average across subjects if you have multiple subjects ---\n",
    "# Store scores for each subject and compute mean at the group level\n",
    "\n",
    "print(\"Time-resolved decoding scores shape:\", scores_mean.shape)\n",
    "print(\"Temporal generalization scores shape:\", temporal_gen_scores.shape)\n",
    "print(\"Cross-decoding scores shape:\", cross_decoding_scores.shape)\n",
    "print(\"Pre-stimulus prediction scores shape:\", pre_stim_scores.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
