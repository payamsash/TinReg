a) Time-Generalized MVPA
Similar to the paper, you could train a classifier on the random condition (least predictable) and then test it across partially and fully ordered sequences.
This allows you to measure how much the brain's predictive pattern generalizes to more predictable contexts—essentially quantifying prediction strength.
b) Regression of Prediction Strength
For each participant, you could compute classifier performance over time and then regress it against the sequence predictability (0.25, 0.75, 1.0).
This gives a slope (β) per subject, reflecting how sensitive their auditory system is to predictability.
You can then compare slopes between tinnitus and control groups, as the paper did.
c) Pre-Stimulus Activity
The paper emphasizes that predictive coding effects appear before stimulus onset.
Focus on time windows before each tone, not just the evoked response, to detect anticipatory differences in tinnitus.
d) Condition-Specific Patterns
You could explore whether certain triggers (e.g., partially ordered sequences) produce intermediate prediction responses.
This helps identify non-linear effects of predictability, since your 75% ordered condition may reveal subtle prediction deficits not visible in fully ordered or fully random sequences.





----------------
b) Extracting Classifier Weights
Classifier weights tell you which sensors/time points contribute most to discriminating the classes.
In the paper, they modified MVPA-Light to extract these weights, allowing them to map neural patterns associated with each tone frequency.
c) Four Target Classes
Each trial presented one of four sound frequencies, so the classifier was trained to predict which frequency was presented based on the MEG/EEG data.
This is a 4-class classification problem.
d) Training Only on Random Sequences
Important: they trained only on the random sequences (least predictable, 25%).
Why?
Random sequences avoid carryover/prediction effects from previous tones.
Ensures the classifier learns pure frequency-related neural templates, not predictive activity.
Once trained, they tested on partially and fully ordered sequences, revealing how predictions modulate neural representations.




------------------
1. Multiclass Linear Discriminant Analysis (LDA)
They trained a multiclass LDA classifier.
Multiclass LDA: a simple linear classifier that finds linear boundaries between multiple classes (here, the 4 sound frequencies).
“On each sample point”:
They trained separate classifiers at each time point (e.g., every millisecond or data sample in the epoch).
This is sometimes called time-resolved decoding, giving accuracy over time for each subject.

2. Averaging Accuracy Across Subjects
After decoding, they averaged the classification accuracy for each subject, then performed group-level comparisons.
This means the reported accuracy curves are mean accuracy across all subjects, giving a robust estimate.

3. Temporal Generalization (King & Dehaene, 2014)
Temporal generalization tests whether the pattern learned at one time point can predict other time points.
Example:
Train on 100–120 ms post-stimulus → test on 150 ms → see if the neural pattern generalizes.
This creates a time × time decoding matrix, showing how stable neural patterns are over time.

4. Cross-Decoding
When testing on ordered sequences:
They did not perform cross-validation because it’s cross-decoding: train on random tones, test on ordered tones.
Cross-validation is only needed when training and testing on the same condition (like random tones) to avoid overfitting.
For testing on random tones:
They did 5-fold cross-validation (splitting random tones into 5 subsets, training on 4, testing on 1, repeated 5 times).

5. Pre- vs Post-Stimulus Training
They trained on post-stimulus intervals (after the tone onset).
Tested on pre-stimulus intervals (before tone onset) for random tones.
Purpose:
This tests for predictive neural activity: can the classifier trained on responses to the sound detect pre-stimulus neural templates, reflecting anticipation or prediction.